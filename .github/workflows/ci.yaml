name: CI

on:
  pull_request:
    branches:
      - development
      
env:
  NAMESPACE: mlrun

jobs:
  lint:
    runs-on: ubuntu-20.04
    container:
      image: artifacthub/ah
      options: --user 1001
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      - name: Run ah lint
        working-directory: ./charts/mlrun-ce
        run: ah lint
  ssh:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v2
    - name: Extract private key
      run: echo "${{ secrets.MLRUN_PEM }}" > mlrun.pem
    - name: Set permissions on key
      run: chmod 400 mlrun.pem
    - name: Install sshpass
      run: sudo apt-get install -y sshpass
    - name: Copy folder to remote machine
      run: sudo scp -r -o StrictHostKeyChecking=no -i mlrun.pem  /home/runner/work/ce ${{ secrets.USERNAME }}@${{ secrets.IP }}:ce
    - name: Run commands on remote machine
      run: |
        sshpass ssh -o StrictHostKeyChecking=no -i  mlrun.pem ${{ secrets.USERNAME }}@${{ secrets.IP }} <<EOF
        
        # CLEANUP
        echo "helm uninstall mlrun-ce"
        helm uninstall -n mlrun mlrun-ce 2>/dev/null
        echo "helm uninstall monitoring"
        helm uninstall -n mlrun monitoring 2>/dev/null
        echo "delete pv, pvc from mlrun"
        kubectl delete pv,pvc --all -n mlrun 2>/dev/null
        
        # CREATING NEW PV, PVC and setting as default
        echo "creating local storage";
        kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.24/deploy/local-path-storage.yaml
        echo "removing default storage class (gp2 is the default on new ce)"
        kubectl patch storageclass gp2 -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"false"}}}' 2>/dev/null
        echo "making new storageclass as default"
        kubectl patch storageclass local-path -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'
        echo "deleting mlrun namepsace";
        kubectl delete namespace mlrun 2>/dev/null
        
        # CE INSTALLATION
        cd ce/ce/charts/mlrun-ce
        echo "helm dependency update"
        helm dependency update
        echo "create mlrun namepsace"
        kubectl create namespace mlrun        
        echo "k8s namespaces - $(kubectl get namespace)"
        echo "installing community edition"
        helm install mlrun-ce --namespace mlrun \
        --set minio.resources.requests.memory="128Mi" \
        --set  jupyterNotebook.persistence.size="1Gi" \
        --set  mlrun.db.persistence.size="1Gi" \
        --set  mlrun.api.persistence.size="1Gi" \
        --set  mpi-operator.deployment.create="false" \
        --set  mlrun.httpDB.dbType="sqlite" \
        --set  mlrun.httpDB.dirPath="/mlrun/db" \
        --set  mlrun.httpDB.dsn="sqlite:////mlrun/db/mlrun.db?check_same_thread=false"  \
        --set  mlrun.httpDB.oldDsn=""  \
        --wait --debug --timeout=1h .

        # RUNNING DEMOS FROM JUPYTER POD
        kubectl -n mlrun get pods
        kubectl -n mlrun get pods --no-headers -o custom-columns=":metadata.name"|grep jupyter| awk '{print $1}'
        kubectl -n mlrun get pods -o name|grep jupyter|head -n 1| cut -d / -f 2 > pod_name.txt
        jupyter_service=$(<pod_name.txt)
        #jupyter_service=$(kubectl -n mlrun get pods --no-headers -o custom-columns=":metadata.name"|grep jupyter| awk '{print $1}')
        #echo "JUPYTER : $jupyter_service"
        #jupyter_service=$(kubectl -n mlrun get pods -o name|grep jupyter|head -n 1| cut -d / -f 2)
        echo "JUPYTER : $jupyter_service"
        
        echo "creating script that run demos"
        echo "echo Running CE supported notebooks;
              echo $(ls);
              echo $(pwd);
              echo news-article-nlp;
              cd demos/news-article-nlp;
              jupyter nbconvert --to script news_article_nlp.ipynb;
              ipython news_article_nlp.py;
              echo mask-detection;
              cd ../mask-detection;
              jupyter nbconvert --to script 1-training-and-evaluation.ipynb;
              ipython 1-training-and-evaluation.py;
              jupyter nbconvert --to script 2-serving.ipynb;
              ipython 2-serving.py;
              jupyter nbconvert --to script 3-automatic-pipeline.ipynb;
              ipython 3-automatic-pipeline.py;
              echo All notebooks ran successfully; " > demos_script.sh
              
        echo "copying demos running script to jupyter"
        echo "mlrun/$jupyter_service:demos_script.sh"
        kubectl cp demos_script.sh mlrun/$jupyter_service:demos_script.sh
        echo "running demos script"
        kubectl exec -n mlrun $jupyter_service -- bash demos_script.sh
        echo "CE demos ci finished"
        
        ###########################
        cd;
        rm -rf ce 2>/dev/null
        EOF
        rm -rf mlrun.pem
        
  
  # commented out for now, takes too long to pull images
  # perhaps we can invoke it via workflow dispatch or as a nightly job
  # test:
  #   runs-on: ubuntu-latest
  #   steps:
  #     - name: Checkout
  #       uses: actions/checkout@v3
  #     - name: Setup Kubernetes cluster
  #       uses: helm/kind-action@v1.4.0
  #       with:
  #         config: ./.github/assets/kind.yaml
  #         wait: 180s
  #         kubectl_version: v1.23.13
  #         node_image: kindest/node:v1.23.13
  #     - name: Setup Helm
  #       uses: azure/setup-helm@v3
  #       with:
  #         token: ${{ secrets.GITHUB_TOKEN }}
  #     - name: Run tests
  #       run : make tests
