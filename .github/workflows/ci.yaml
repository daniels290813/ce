name: CI

on:
  pull_request:
    branches:
      - development
      
env:
  NAMESPACE: mlrun

jobs:
  lint:
    runs-on: ubuntu-20.04
    container:
      image: artifacthub/ah
      options: --user 1001
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      - name: Run ah lint
        working-directory: ./charts/mlrun-ce
        run: ah lint
  ssh:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v2
    - name: Extract private key
      run: echo "${{ secrets.MLRUN_PEM }}" > mlrun.pem
    - name: Set permissions on key
      run: chmod 400 mlrun.pem
    - name: Install sshpass
      run: sudo apt-get install -y sshpass
    - name: Copy folder to remote machine
      run: sudo scp -r -o StrictHostKeyChecking=no -i mlrun.pem  /home/runner/work/ce ${{ secrets.USERNAME }}@${{ secrets.IP }}:ce
    - name: Run commands on remote machine
      run: |
        sshpass ssh -o StrictHostKeyChecking=no -i  mlrun.pem ${{ secrets.USERNAME }}@${{ secrets.IP }} <<EOF
        # CLEANUP
        echo Deleting mlrun namepsace;
        helm uninstall -n mlrun mlrun-ce 2>/dev/null
        echo Deleting mlrun namepsace2;
        helm uninstall -n mlrun monitoring 2>/dev/null
        echo Deleting mlrun namepsace3;
        kubectl delete pv,pvc --all -n mlrun 2>/dev/null
        # CREATING NEW PV, PVC and setting as default
        echo "adding pv (local-path)";
        kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.24/deploy/local-path-storage.yaml
        echo "removing default storage class if existsif exists (gp2 is the default)";
        kubectl patch storageclass gp2 -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"false"}}}' 2>/dev/null
        echo making new storageclass as default;
        kubectl patch storageclass local-path -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'
        echo Deleting mlrun namepsace;
        kubectl delete namespace mlrun 2>/dev/null
        
        # CE INSTALLATION
        cd ce/ce/charts/mlrun-ce
        echo helm dependency update;
        helm dependency update
        echo create mlrun namepsace;
        kubectl create namespace mlrun        
        echo "installing Community Edition"
        helm install mlrun-ce --namespace ${NAMESPACE} \
        --set minio.resources.requests.memory="128Mi" \
        --set  jupyterNotebook.persistence.size="1Gi" \
        --set  mlrun.db.persistence.size="1Gi" \
        --set  mlrun.api.persistence.size="1Gi" \
        --set  mpi-operator.deployment.create="false" \
        --set  mlrun.httpDB.dbType="sqlite" \
        --set  mlrun.httpDB.dirPath="/mlrun/db" \
        --set  mlrun.httpDB.dsn="sqlite:////mlrun/db/mlrun.db?check_same_thread=false"  \
        --set  mlrun.httpDB.oldDsn=""  \
        --wait --debug --timeout=1h .
        # TO-DO add demos execution
        ##########################
        # RUNNING DEMOS FROM JUPYTER POD
        echo Creating script to run demos;
        jupyter_service=$(kubectl -n mlrun get pods --no-headers -o custom-columns=":metadata.name"|grep jupyter)
        echo $jupyter_service
        echo "echo Running CE supported notebooks;
              echo news-article-nlp;
              cd home/jovyan/demos/news-article-nlp;
              jupyter nbconvert --to script news_article_nlp.ipynb;
              ipython news_article_nlp.py;
              echo mask-detection;
              cd home/jovyan/demos/mask-detection;
              jupyter nbconvert --to script 1-training-and-evaluation.ipynb;
              ipython 1-training-and-evaluation.py;
              jupyter nbconvert --to script 2-serving.ipynb;
              ipython 2-serving.py;
              jupyter nbconvert --to script 3-automatic-pipeline.ipynb;
              ipython 3-automatic-pipeline.py;
              echo All notebooks ran successfully; " > demos_script.sh
              
        echo COPYING DEMO SCRIPT TO JUPYTER POD;
        echo "Copying demos running script to jupyter pod"
        kubectl cp $(pwd)/demos_script.sh mlrun/$jupyter_service:/home/jovyan/demos_script.sh
        echo "Running demos script"
        kubectl exec -n mlrun $jupyter_service -- bash /home/jovyan/demos_script.sh
        echo "CE demos ci finished"
        
        ###########################
        cd;
        rm -rf ce 2>/dev/null
        EOF
        rm -rf mlrun.pem
        
  
  # commented out for now, takes too long to pull images
  # perhaps we can invoke it via workflow dispatch or as a nightly job
  # test:
  #   runs-on: ubuntu-latest
  #   steps:
  #     - name: Checkout
  #       uses: actions/checkout@v3
  #     - name: Setup Kubernetes cluster
  #       uses: helm/kind-action@v1.4.0
  #       with:
  #         config: ./.github/assets/kind.yaml
  #         wait: 180s
  #         kubectl_version: v1.23.13
  #         node_image: kindest/node:v1.23.13
  #     - name: Setup Helm
  #       uses: azure/setup-helm@v3
  #       with:
  #         token: ${{ secrets.GITHUB_TOKEN }}
  #     - name: Run tests
  #       run : make tests
